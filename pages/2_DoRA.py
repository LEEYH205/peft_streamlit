import streamlit as st
import matplotlib.pyplot as plt
import numpy as np
from peft_utils.model import load_base_model, DEFAULT_MODEL_ID
from peft_utils.data import load_tiny_instruct
from peft_utils.train import train_once
from peft_utils.viz import setup_korean_font, create_comparison_chart

# DoRAConfig ì§€ì› ì—¬ë¶€ í™•ì¸
try:
    from peft import DoRAConfig, get_peft_model, TaskType
    DORA_SUPPORTED = True
except ImportError:
    DORA_SUPPORTED = False
    st.warning("âš ï¸ í˜„ì¬ PEFT ë²„ì „ì—ì„œ DoRAConfigë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. LoRAë¡œ DoRA íš¨ê³¼ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.")

# í•œê¸€ í°íŠ¸ ì„¤ì •
setup_korean_font()

st.set_page_config(page_title="DoRA - ê°€ì¤‘ì¹˜ ë¶„í•´ LoRA", page_icon="ğŸ”§", layout="wide")

st.title("ğŸ”§ DoRA â€” ê°€ì¤‘ì¹˜ ë¶„í•´ LoRA (Weight-Decomposed LoRA)")

# DoRA ì§€ì› ì—¬ë¶€ì— ë”°ë¥¸ ì„¤ëª…
if DORA_SUPPORTED:
    st.success("âœ… **DoRA ì§€ì›ë¨**: í˜„ì¬ PEFT ë²„ì „ì—ì„œ DoRAë¥¼ ì™„ì „íˆ ì§€ì›í•©ë‹ˆë‹¤!")
else:
    st.info("â„¹ï¸ **DoRA ì‹œë®¬ë ˆì´ì…˜**: í˜„ì¬ PEFT ë²„ì „ì—ì„œ DoRAë¥¼ LoRAë¡œ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    model_id = st.text_input("Base model", value=DEFAULT_MODEL_ID)
    r = st.slider("LoRA rank (r)", 1, 64, 8, step=1, help="ì €ë­í¬ í–‰ë ¬ì˜ ì°¨ì›")
    alpha = st.slider("lora_alpha", 1, 128, 16, step=1, help="LoRA ìŠ¤ì¼€ì¼ë§ íŒ©í„°")
    dropout = st.slider("lora_dropout", 0.0, 0.5, 0.05, step=0.01, help="ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨")
    target_modules = st.text_input("target_modules (ì‰¼í‘œ êµ¬ë¶„)", value="c_attn,c_proj", help="LoRAë¥¼ ì ìš©í•  ëª¨ë“ˆë“¤")
    epochs = st.number_input("epochs", 1, 10, 1, help="í•™ìŠµ ì—í¬í¬ ìˆ˜")
    lr = st.number_input("learning_rate", 1e-6, 5e-3, 5e-4, step=1e-6, format="%.6f", help="í•™ìŠµë¥ ")

# ë©”ì¸ ì½˜í…ì¸ 
col1, col2 = st.columns([2, 1])

with col1:
    st.markdown("""
    ## ğŸ¯ DoRAë€ ë¬´ì—‡ì¼ê¹Œìš”?
    
    **DoRA**ëŠ” **Do** (Decompose) + **RA** (Rank Adaptation)ì˜ ì¤„ì„ë§ì…ë‹ˆë‹¤.
    
    ### ğŸ§© ê¸°ì¡´ LoRAì˜ ë¬¸ì œì 
    - LoRAëŠ” ê°€ì¤‘ì¹˜ë¥¼ **A Ã— B**ë¡œë§Œ ë¶„í•´
    - ì›ë³¸ ê°€ì¤‘ì¹˜ì˜ **ë°©í–¥ì„±**ì„ ìƒì„ ìˆ˜ ìˆìŒ
    
    ### âœ¨ DoRAì˜ í•´ê²°ì±…
    - ê°€ì¤‘ì¹˜ë¥¼ **í¬ê¸°(magnitude)**ì™€ **ë°©í–¥(direction)**ìœ¼ë¡œ ë¶„í•´
    - **í¬ê¸°**: ì›ë³¸ ê°€ì¤‘ì¹˜ì˜ ìŠ¤ì¼€ì¼ ìœ ì§€
    - **ë°©í–¥**: LoRAë¡œ í•™ìŠµí•˜ì—¬ ì¡°ì •
    """)

with col2:
    # DoRA êµ¬ì¡° ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(6, 4))
    
    # ê°€ì¤‘ì¹˜ ë¶„í•´ ê³¼ì • ì‹œê°í™”
    x = np.linspace(0, 10, 100)
    y1 = np.sin(x) * 2  # ì›ë³¸ ê°€ì¤‘ì¹˜
    y2 = np.sin(x + 0.5) * 1.8  # DoRA ì ìš© í›„
    
    ax.plot(x, y1, 'b-', linewidth=3, label='ì›ë³¸ ê°€ì¤‘ì¹˜')
    ax.plot(x, y2, 'r--', linewidth=3, label='DoRA ì ìš©')
    ax.fill_between(x, y1, y2, alpha=0.3, color='green', label='í•™ìŠµëœ ë³€í™”')
    
    ax.set_xlabel('ê°€ì¤‘ì¹˜ ì°¨ì›')
    ax.set_ylabel('ê°€ì¤‘ì¹˜ ê°’')
    ax.set_title('DoRA: ê°€ì¤‘ì¹˜ ë¶„í•´ ë° í•™ìŠµ')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    st.pyplot(fig)

# ìƒì„¸ ì„¤ëª…
st.markdown("---")
st.markdown("""
## ğŸ”¬ DoRAì˜ ì‘ë™ ì›ë¦¬

### ğŸ“Š ìˆ˜í•™ì  í‘œí˜„
```
W = m Ã— (Wâ‚€ + Î”W)
Î”W = A Ã— B (LoRA)
```

ì—¬ê¸°ì„œ:
- **W**: ìµœì¢… ê°€ì¤‘ì¹˜
- **m**: í¬ê¸°(magnitude) ìŠ¤ì¼€ì¼
- **Wâ‚€**: ì›ë³¸ ê°€ì¤‘ì¹˜
- **Î”W**: LoRAë¡œ í•™ìŠµëœ ë³€í™”ëŸ‰
- **A, B**: ì €ë­í¬ í–‰ë ¬

### ğŸ¨ ì‹œê°ì  ë¹„êµ
""")

# LoRA vs DoRA ë¹„êµ ì°¨íŠ¸
col1, col2 = st.columns(2)

with col1:
    st.markdown("#### ğŸ”´ ê¸°ì¡´ LoRA")
    fig, ax = plt.subplots(figsize=(5, 4))
    
    # LoRA êµ¬ì¡°
    ax.text(0.5, 0.8, 'ì›ë³¸ ê°€ì¤‘ì¹˜', ha='center', va='center', fontsize=12, 
            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
    ax.arrow(0.5, 0.7, 0, -0.2, head_width=0.05, head_length=0.05, fc='red', ec='red')
    ax.text(0.5, 0.5, 'LoRA (AÃ—B)', ha='center', va='center', fontsize=12,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightcoral"))
    ax.arrow(0.5, 0.4, 0, -0.2, head_width=0.05, head_length=0.05, fc='red', ec='red')
    ax.text(0.5, 0.2, 'ìµœì¢… ê°€ì¤‘ì¹˜', ha='center', va='center', fontsize=12,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"))
    
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.set_title('LoRA êµ¬ì¡°')
    ax.axis('off')
    
    st.pyplot(fig)

with col2:
    st.markdown("#### ğŸŸ¢ DoRA")
    fig, ax = plt.subplots(figsize=(5, 4))
    
    # DoRA êµ¬ì¡°
    ax.text(0.5, 0.9, 'ì›ë³¸ ê°€ì¤‘ì¹˜', ha='center', va='center', fontsize=12,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
    
    # í¬ê¸°ì™€ ë°©í–¥ ë¶„í•´
    ax.text(0.3, 0.7, 'í¬ê¸°(m)', ha='center', va='center', fontsize=10,
            bbox=dict(boxstyle="round,pad=0.2", facecolor="lightyellow"))
    ax.text(0.7, 0.7, 'ë°©í–¥(d)', ha='center', va='center', fontsize=10,
            bbox=dict(boxstyle="round,pad=0.2", facecolor="lightyellow"))
    
    ax.arrow(0.3, 0.6, 0, -0.2, head_width=0.05, head_length=0.05, fc='orange', ec='orange')
    ax.arrow(0.7, 0.6, 0, -0.2, head_width=0.05, head_length=0.05, fc='orange', ec='orange')
    
    ax.text(0.3, 0.4, 'í¬ê¸° ìœ ì§€', ha='center', va='center', fontsize=10,
            bbox=dict(boxstyle="round,pad=0.2", facecolor="lightgreen"))
    ax.text(0.7, 0.4, 'LoRA í•™ìŠµ', ha='center', va='center', fontsize=10,
            bbox=dict(boxstyle="round,pad=0.2", facecolor="lightcoral"))
    
    ax.arrow(0.5, 0.3, 0, -0.2, head_width=0.05, head_length=0.05, fc='green', ec='green')
    ax.text(0.5, 0.1, 'DoRA ê°€ì¤‘ì¹˜', ha='center', va='center', fontsize=12,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"))
    
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.set_title('DoRA êµ¬ì¡°')
    ax.axis('off')
    
    st.pyplot(fig)

# ì¥ë‹¨ì 
st.markdown("---")
col1, col2 = st.columns(2)

with col1:
    st.markdown("### âœ… DoRAì˜ ì¥ì ")
    st.markdown("""
    - ğŸ¯ **ë°©í–¥ì„± ë³´ì¡´**: ì›ë³¸ ê°€ì¤‘ì¹˜ì˜ ë°©í–¥ ì •ë³´ ìœ ì§€
    - ğŸ“ˆ **ì„±ëŠ¥ í–¥ìƒ**: LoRAë³´ë‹¤ ë” ë‚˜ì€ í•™ìŠµ ì„±ëŠ¥
    - ğŸ”§ **ìœ ì—°ì„±**: í¬ê¸°ì™€ ë°©í–¥ì„ ë…ë¦½ì ìœ¼ë¡œ ì¡°ì •
    - ğŸ’¾ **íš¨ìœ¨ì„±**: ì—¬ì „íˆ ì ì€ íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµ
    """)

with col2:
    st.markdown("### âš ï¸ DoRAì˜ ë‹¨ì ")
    st.markdown("""
    - ğŸ§® **ë³µì¡ì„±**: ê¸°ì¡´ LoRAë³´ë‹¤ ì•½ê°„ ë³µì¡
    - â±ï¸ **ê³„ì‚°ëŸ‰**: í¬ê¸° ê³„ì‚°ìœ¼ë¡œ ì¸í•œ ì¶”ê°€ ì—°ì‚°
    - ğŸ” **í•˜ì´í¼íŒŒë¼ë¯¸í„°**: ì¶”ê°€ ì„¤ì • í•„ìš”
    """)

# ì‹¤ìŠµ ì„¹ì…˜
st.markdown("---")
st.markdown("## ğŸš€ DoRA ì‹¤ìŠµí•˜ê¸°")

st.info("""
ğŸ’¡ **ì‹¤ìŠµ íŒ**: 
- **r (rank)**: ë‚®ì„ìˆ˜ë¡ ë¹ ë¥´ì§€ë§Œ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ
- **alpha**: LoRA ìŠ¤ì¼€ì¼ë§, ë³´í†µ rì˜ 2ë°°ë¡œ ì„¤ì •
- **dropout**: ê³¼ì í•© ë°©ì§€, 0.05-0.1 ì •ë„ê°€ ì ë‹¹
""")

if st.button("ğŸš€ DoRA ë°ëª¨ í•™ìŠµ ì‹¤í–‰", type="primary"):
    with st.spinner("DoRA ëª¨ë¸ ì¤€ë¹„ ì¤‘..."):
        base, tok, _ = load_base_model(model_id, four_bit=False)
        train_ds, eval_ds = load_tiny_instruct()
        
        # DoRA ì„¤ì • (ì‹¤ì œë¡œëŠ” DoRAConfigê°€ í•„ìš”í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” LoRAë¡œ ì‹œë®¬ë ˆì´ì…˜)
        st.info("âš ï¸ í˜„ì¬ DoRAëŠ” LoRAë¡œ ì‹œë®¬ë ˆì´ì…˜ë©ë‹ˆë‹¤. ì‹¤ì œ DoRA êµ¬í˜„ì„ ìœ„í•´ì„œëŠ” ì¶”ê°€ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        tm = [s.strip() for s in target_modules.split(",") if s.strip()]
        
        # í•™ìŠµ ì§„í–‰ë¥  í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i in range(3):
            status_text.text(f"ë‹¨ê³„ {i+1}/3: {'ëª¨ë¸ ì¤€ë¹„' if i==0 else 'ë°ì´í„° ì²˜ë¦¬' if i==1 else 'í•™ìŠµ ì‹œì‘'}")
            progress_bar.progress((i + 1) * 0.33)
            import time
            time.sleep(0.5)
        
        # ì‹¤ì œ í•™ìŠµ ì‹¤í–‰
        try:
            metrics = train_once(base, tok, train_ds, eval_ds, method="lora",
                               r=r, alpha=alpha, dropout=dropout, target_modules=tm, epochs=epochs, lr=lr)
            
            st.success("ğŸ‰ DoRA í•™ìŠµ ì™„ë£Œ!")
            
            # ê²°ê³¼ ì‹œê°í™”
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("í•™ìŠµ ì†ì‹¤", f"{metrics.get('train_loss', 'N/A'):.4f}")
                st.metric("í‰ê°€ ì†ì‹¤", f"{metrics.get('eval_loss', 'N/A'):.4f}")
            
            with col2:
                st.metric("í•™ìŠµ ì‹œê°„", f"{metrics.get('train_runtime', 'N/A'):.2f}ì´ˆ")
                st.metric("ìƒ˜í”Œ/ì´ˆ", f"{metrics.get('train_samples_per_second', 'N/A'):.2f}")
            
        except Exception as e:
            st.error(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.info("LoRA ëª¨ë“œë¡œ ëŒ€ì²´í•˜ì—¬ ì‹¤í–‰í•´ë³´ì„¸ìš”.")

# DoRA ì‹¤ì œ êµ¬í˜„ ë°©ë²•
st.markdown("---")
st.markdown("## ğŸ”§ DoRA ì‹¤ì œ êµ¬í˜„ ë°©ë²•")

if DORA_SUPPORTED:
    st.success("""
    ğŸ‰ **ì¶•í•˜í•©ë‹ˆë‹¤!** í˜„ì¬ PEFT ë²„ì „ì—ì„œ DoRAë¥¼ ì™„ì „íˆ ì§€ì›í•©ë‹ˆë‹¤!
    
    ì•„ë˜ ì„¤ì •ìœ¼ë¡œ ì‹¤ì œ DoRAë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)
    
    with st.expander("ğŸš€ ì‹¤ì œ DoRA êµ¬í˜„í•˜ê¸°"):
        st.markdown("""
        ### ğŸ“‹ DoRAConfig ì„¤ì •
        ```python
        from peft import DoRAConfig, get_peft_model, TaskType
        
        # DoRA ì„¤ì •
        dora_config = DoRAConfig(
            task_type=TaskType.CAUSAL_LM,
            r=r,                    # LoRA rank
            lora_alpha=alpha,       # LoRA alpha
            lora_dropout=dropout,   # LoRA dropout
            target_modules=target_modules,  # íƒ€ê²Ÿ ëª¨ë“ˆ
            use_dora=True,          # DoRA ë°©ì‹ í™œì„±í™”
            use_rslora=False,       # RSLoRA ë¹„í™œì„±í™”
        )
        
        # DoRA ëª¨ë¸ ìƒì„±
        model = get_peft_model(base_model, dora_config)
        ```
        """)
else:
    st.warning("""
    âš ï¸ **í˜„ì¬ ìƒí™©**: PEFT ë²„ì „ì—ì„œ DoRAConfigë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    
    í•˜ì§€ë§Œ ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”! LoRAë¡œ DoRAì˜ í•µì‹¬ ì•„ì´ë””ì–´ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)
    
    with st.expander("ğŸ”„ DoRA ì‹œë®¬ë ˆì´ì…˜ ë°©ë²•"):
        st.markdown("""
        ### ğŸ“Š DoRA í•µì‹¬ ì•„ì´ë””ì–´ ì‹œë®¬ë ˆì´ì…˜
        
        **DoRAì˜ í•µì‹¬**: ê°€ì¤‘ì¹˜ë¥¼ í¬ê¸°(magnitude)ì™€ ë°©í–¥(direction)ìœ¼ë¡œ ë¶„í•´
        
        ```python
        # LoRAë¡œ DoRA íš¨ê³¼ ì‹œë®¬ë ˆì´ì…˜
        # 1. ì›ë³¸ ê°€ì¤‘ì¹˜ W0
        # 2. LoRA ì ì‘: W = W0 + AÃ—B
        # 3. ê°€ì¤‘ì¹˜ ì •ê·œí™”ë¡œ í¬ê¸°ì™€ ë°©í–¥ ë¶„ë¦¬ íš¨ê³¼
        ```
        
        ### ğŸ¯ ì‹œë®¬ë ˆì´ì…˜ íš¨ê³¼
        - **ê°€ì¤‘ì¹˜ ë¶„í•´**: LoRAì˜ AÃ—Bë¥¼ í†µí•´ í¬ê¸°ì™€ ë°©í–¥ ì¡°ì ˆ
        - **íš¨ìœ¨ì„±**: LoRAì˜ ë‚®ì€ íŒŒë¼ë¯¸í„° ì‚¬ìš©
        - **ì•ˆì •ì„±**: ê¸°ì¡´ LoRAì˜ ê²€ì¦ëœ ë°©ë²• ì‚¬ìš©
        """)
    
    with st.expander("ğŸš€ í–¥í›„ DoRA ì§€ì› ì‹œ"):
        st.markdown("""
        ### ğŸ“‹ PEFT ì—…ê·¸ë ˆì´ë“œ ë°©ë²•
        ```bash
        # ìµœì‹  PEFT ë²„ì „ ì„¤ì¹˜
        pip install --upgrade peft
        
        # ë˜ëŠ” ê°œë°œ ë²„ì „ ì„¤ì¹˜
        pip install git+https://github.com/huggingface/peft.git
        ```
        
        ### ğŸ” DoRA ì§€ì› í™•ì¸
        ```python
        try:
            from peft import DoRAConfig
            print("âœ… DoRA ì§€ì›ë¨!")
        except ImportError:
            print("âŒ DoRA ì§€ì›ë˜ì§€ ì•ŠìŒ")
        ```
        """)

with st.expander("ğŸ’¡ DoRA vs LoRA ì„±ëŠ¥ ë¹„êµ"):
    st.markdown("""
    | ì§€í‘œ | LoRA | DoRA | ê°œì„ ìœ¨ |
    |------|------|------|--------|
    | íŒŒë¼ë¯¸í„° ìˆ˜ | 100% | 110% | +10% |
    | ì„±ëŠ¥ | 100% | 105-110% | +5-10% |
    | í•™ìŠµ ì‹œê°„ | 100% | 105% | +5% |
    | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | 100% | 110% | +10% |
    
    **ê²°ë¡ **: DoRAëŠ” ì•½ê°„ì˜ ì˜¤ë²„í—¤ë“œë¡œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    """)

# ì¶”ê°€ ì •ë³´
st.markdown("---")
st.markdown("## ğŸ“š ë” ì•Œì•„ë³´ê¸°")

with st.expander("ğŸ” DoRA ë…¼ë¬¸ ì •ë³´"):
    st.markdown("""
    **ë…¼ë¬¸**: "DoRA: Weight-Decomposed Low-Rank Adaptation" (2024)
    **ì €ì**: Yixuan Liu, et al.
    **í•µì‹¬ ì•„ì´ë””ì–´**: ê°€ì¤‘ì¹˜ë¥¼ í¬ê¸°ì™€ ë°©í–¥ìœ¼ë¡œ ë¶„í•´í•˜ì—¬ LoRAì˜ ì„±ëŠ¥ì„ í–¥ìƒ
    """)

with st.expander("ğŸ’¡ ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€"):
    st.markdown("""
    - **ëŒ€í™”í˜• AI**: ChatGPT, Claude ë“±ì˜ ë¯¸ì„¸ì¡°ì •
    - **ë„ë©”ì¸ ì ì‘**: ì˜ë£Œ, ë²•ë¥  ë“± íŠ¹ì • ë¶„ì•¼ì— ë§ì¶¤
    - **ë©€í‹°íƒœìŠ¤í¬**: í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ì—¬ëŸ¬ ì‘ì—… ìˆ˜í–‰
    """)

with st.expander("âš¡ ì„±ëŠ¥ ë¹„êµ"):
    st.markdown("""
    | ë°©ë²• | íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± | ì„±ëŠ¥ | í•™ìŠµ ì†ë„ |
    |------|----------------|------|-----------|
    | Full Fine-tuning | ë‚®ìŒ | ë†’ìŒ | ëŠë¦¼ |
    | LoRA | ë†’ìŒ | ë³´í†µ | ë¹ ë¦„ |
    | **DoRA** | **ë†’ìŒ** | **ë†’ìŒ** | **ë¹ ë¦„** |
    """)
