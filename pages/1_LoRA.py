import matplotlib.pyplot as plt
import numpy as np
import streamlit as st

from peft_utils.data import load_tiny_instruct
from peft_utils.model import DEFAULT_MODEL_ID, load_base_model
from peft_utils.train import train_once

st.set_page_config(page_title="LoRA - ì €ë­í¬ ì ì‘", page_icon="ğŸ”§", layout="wide")

st.title("ğŸ”§ LoRA â€” ì €ë­í¬ ì ì‘ (Low-Rank Adaptation)")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    model_id = st.text_input("Base model", value=DEFAULT_MODEL_ID, help="ê¸°ë³¸ ëª¨ë¸ ID")
    r = st.slider(
        "LoRA rank (r)",
        1,
        64,
        8,
        step=1,
        help="ì €ë­í¬ í–‰ë ¬ì˜ ì°¨ì› (ë‚®ì„ìˆ˜ë¡ ë¹ ë¥´ì§€ë§Œ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ)",
    )
    alpha = st.slider(
        "lora_alpha",
        1,
        128,
        16,
        step=1,
        help="LoRA ìŠ¤ì¼€ì¼ë§ íŒ©í„° (ë³´í†µ rì˜ 2ë°°ë¡œ ì„¤ì •)",
    )
    dropout = st.slider(
        "lora_dropout", 0.0, 0.5, 0.05, step=0.01, help="ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ (ê³¼ì í•© ë°©ì§€)"
    )
    target_modules = st.text_input(
        "target_modules (ì‰¼í‘œ êµ¬ë¶„)", value="c_attn,c_proj", help="LoRAë¥¼ ì ìš©í•  ëª¨ë“ˆë“¤"
    )
    epochs = st.number_input("epochs", 1, 10, 1, help="í•™ìŠµ ì—í¬í¬ ìˆ˜")
    lr = st.number_input(
        "learning_rate", 1e-6, 5e-3, 5e-4, step=1e-6, format="%.6f", help="í•™ìŠµë¥ "
    )

# ë©”ì¸ ì½˜í…ì¸ 
col1, col2 = st.columns([2, 1])

with col1:
    st.markdown(
        """
    ## ğŸ¯ LoRAë€ ë¬´ì—‡ì¼ê¹Œìš”?

    **LoRA**ëŠ” **Lo**w-**Ra**nk Adaptationì˜ ì¤„ì„ë§ì…ë‹ˆë‹¤.

    ### ğŸ§© ê¸°ì¡´ ë¯¸ì„¸ì¡°ì •ì˜ ë¬¸ì œì 
    - **ì „ì²´ íŒŒë¼ë¯¸í„° í•™ìŠµ**: ìˆ˜ì–µ~ìˆ˜ì²œì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ëª¨ë‘ í•™ìŠµ
    - **ë©”ëª¨ë¦¬ ë¶€ì¡±**: GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ì—¬ í•™ìŠµ ë¶ˆê°€
    - **ëŠë¦° í•™ìŠµ**: ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•´ì•¼ í•¨

    ### âœ¨ LoRAì˜ í•´ê²°ì±…
    - **ì €ë­í¬ ë¶„í•´**: ê°€ì¤‘ì¹˜ë¥¼ A Ã— Bë¡œ ë¶„í•´í•˜ì—¬ í•™ìŠµ
    - **íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„±**: ì „ì²´ì˜ 0.1% ë¯¸ë§Œì˜ íŒŒë¼ë¯¸í„°ë§Œ í•™ìŠµ
    - **ë¹ ë¥¸ í•™ìŠµ**: ì‘ì€ í–‰ë ¬ë§Œ ì—…ë°ì´íŠ¸í•˜ì—¬ ë¹ ë¦„
    """
    )

with col2:
    # LoRA êµ¬ì¡° ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(6, 4))

    # ê°€ì¤‘ì¹˜ ë¶„í•´ ê³¼ì • ì‹œê°í™”
    x = np.linspace(0, 10, 100)
    y1 = np.sin(x) * 2  # ì›ë³¸ ê°€ì¤‘ì¹˜
    y2 = np.sin(x + 0.3) * 1.8  # LoRA ì ìš© í›„

    ax.plot(x, y1, "b-", linewidth=3, label="ì›ë³¸ ê°€ì¤‘ì¹˜")
    ax.plot(x, y2, "r--", linewidth=3, label="LoRA ì ìš©")
    ax.fill_between(x, y1, y2, alpha=0.3, color="green", label="í•™ìŠµëœ ë³€í™”")

    ax.set_xlabel("ê°€ì¤‘ì¹˜ ì°¨ì›")
    ax.set_ylabel("ê°€ì¤‘ì¹˜ ê°’")
    ax.set_title("LoRA: ì €ë­í¬ ë¶„í•´ ë° í•™ìŠµ")
    ax.legend()
    ax.grid(True, alpha=0.3)

    st.pyplot(fig)

# ìƒì„¸ ì„¤ëª…
st.markdown("---")
st.markdown(
    """
## ğŸ”¬ LoRAì˜ ì‘ë™ ì›ë¦¬

### ğŸ“Š ìˆ˜í•™ì  í‘œí˜„
```
W = Wâ‚€ + Î”W
Î”W = A Ã— B
```

ì—¬ê¸°ì„œ:
- **W**: ìµœì¢… ê°€ì¤‘ì¹˜
- **Wâ‚€**: ì›ë³¸ ê°€ì¤‘ì¹˜ (ê³ ì •, í•™ìŠµ ì•ˆí•¨)
- **Î”W**: LoRAë¡œ í•™ìŠµëœ ë³€í™”ëŸ‰
- **A**: r Ã— d í–‰ë ¬ (í•™ìŠµ ê°€ëŠ¥)
- **B**: d Ã— r í–‰ë ¬ (í•™ìŠµ ê°€ëŠ¥)
- **r**: rank (ì°¨ì›, ë³´í†µ 8-64)

### ğŸ¨ ì‹œê°ì  êµ¬ì¡°
"""
)

# LoRA êµ¬ì¡° ì‹œê°í™”
col1, col2 = st.columns(2)

with col1:
    st.markdown("#### ğŸ”´ ê¸°ì¡´ ë¯¸ì„¸ì¡°ì •")
    fig, ax = plt.subplots(figsize=(5, 4))

    # ì „ì²´ íŒŒë¼ë¯¸í„° í•™ìŠµ
    ax.text(
        0.5,
        0.8,
        "ì›ë³¸ ê°€ì¤‘ì¹˜",
        ha="center",
        va="center",
        fontsize=12,
        bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"),
    )
    ax.arrow(0.5, 0.7, 0, -0.2, head_width=0.05, head_length=0.05, fc="red", ec="red")
    ax.text(
        0.5,
        0.5,
        "ì „ì²´ íŒŒë¼ë¯¸í„° í•™ìŠµ",
        ha="center",
        va="center",
        fontsize=12,
        bbox=dict(boxstyle="round,pad=0.3", facecolor="lightcoral"),
    )
    ax.arrow(0.5, 0.4, 0, -0.2, head_width=0.05, head_length=0.05, fc="red", ec="red")
    ax.text(
        0.5,
        0.2,
        "ë¯¸ì„¸ì¡°ì •ëœ ê°€ì¤‘ì¹˜",
        ha="center",
        va="center",
        fontsize=12,
        bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"),
    )

    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.set_title("ì „ì²´ ë¯¸ì„¸ì¡°ì •")
    ax.axis("off")

    st.pyplot(fig)

with col2:
    st.markdown("#### ğŸŸ¢ LoRA")
    fig, ax = plt.subplots(figsize=(5, 4))

    # LoRA êµ¬ì¡°
    ax.text(
        0.5,
        0.9,
        "ì›ë³¸ ê°€ì¤‘ì¹˜ (ê³ ì •)",
        ha="center",
        va="center",
        fontsize=12,
        bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"),
    )

    # A, B í–‰ë ¬
    ax.text(
        0.3,
        0.7,
        "A í–‰ë ¬ (rÃ—d)",
        ha="center",
        va="center",
        fontsize=10,
        bbox=dict(boxstyle="round,pad=0.2", facecolor="lightyellow"),
    )
    ax.text(
        0.7,
        0.7,
        "B í–‰ë ¬ (dÃ—r)",
        ha="center",
        va="center",
        fontsize=10,
        bbox=dict(boxstyle="round,pad=0.2", facecolor="lightyellow"),
    )

    ax.arrow(
        0.3, 0.6, 0, -0.2, head_width=0.05, head_length=0.05, fc="orange", ec="orange"
    )
    ax.arrow(
        0.7, 0.6, 0, -0.2, head_width=0.05, head_length=0.05, fc="orange", ec="orange"
    )

    ax.text(
        0.3,
        0.4,
        "A í•™ìŠµ",
        ha="center",
        va="center",
        fontsize=10,
        bbox=dict(boxstyle="round,pad=0.2", facecolor="lightgreen"),
    )
    ax.text(
        0.7,
        0.4,
        "B í•™ìŠµ",
        ha="center",
        va="center",
        fontsize=10,
        bbox=dict(boxstyle="round,pad=0.2", facecolor="lightgreen"),
    )

    ax.arrow(
        0.5, 0.3, 0, -0.2, head_width=0.05, head_length=0.05, fc="green", ec="green"
    )
    ax.text(
        0.5,
        0.1,
        "LoRA ê°€ì¤‘ì¹˜",
        ha="center",
        va="center",
        fontsize=12,
        bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"),
    )

    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.set_title("LoRA êµ¬ì¡°")
    ax.axis("off")

    st.pyplot(fig)

# íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± ë¹„êµ
st.markdown("---")
st.markdown("## ğŸ’¾ íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± ë¹„êµ")

col1, col2 = st.columns(2)

with col1:
    st.markdown("### ğŸ“Š íŒŒë¼ë¯¸í„° ìˆ˜ ë¹„êµ")

    # íŒŒë¼ë¯¸í„° ìˆ˜ ë¹„êµ ì°¨íŠ¸
    methods = ["Full Fine-tuning", "LoRA (r=8)", "LoRA (r=16)", "LoRA (r=32)"]
    param_counts = [100, 0.8, 1.6, 3.2]  # ë°±ë¶„ìœ¨ë¡œ í‘œì‹œ

    fig, ax = plt.subplots(figsize=(6, 4))
    bars = ax.bar(
        methods,
        param_counts,
        color=["red", "lightgreen", "green", "darkgreen"],
        alpha=0.7,
    )
    ax.set_ylabel("í•™ìŠµ íŒŒë¼ë¯¸í„° (%)")
    ax.set_title("íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± ë¹„êµ")
    ax.set_ylim(0, 110)

    # ê°’ í‘œì‹œ
    for bar, count in zip(bars, param_counts):
        height = bar.get_height()
        ax.text(
            bar.get_x() + bar.get_width() / 2.0,
            height + 1,
            f"{count}%",
            ha="center",
            va="bottom",
        )

    st.pyplot(fig)

with col2:
    st.markdown("### âš¡ í•™ìŠµ ì†ë„ ë¹„êµ")

    # í•™ìŠµ ì†ë„ ë¹„êµ
    speed_data = [1, 5, 10, 15]  # ìƒëŒ€ì  ì†ë„

    fig, ax = plt.subplots(figsize=(6, 4))
    bars = ax.bar(
        methods,
        speed_data,
        color=["red", "lightgreen", "green", "darkgreen"],
        alpha=0.7,
    )
    ax.set_ylabel("ìƒëŒ€ì  í•™ìŠµ ì†ë„")
    ax.set_title("í•™ìŠµ ì†ë„ ë¹„êµ")
    ax.set_ylim(0, 20)

    # ê°’ í‘œì‹œ
    for bar, speed in zip(bars, speed_data):
        height = bar.get_height()
        ax.text(
            bar.get_x() + bar.get_width() / 2.0,
            height + 0.5,
            f"{speed}x",
            ha="center",
            va="bottom",
        )

    st.pyplot(fig)

# ì¥ë‹¨ì 
st.markdown("---")
col1, col2 = st.columns(2)

with col1:
    st.markdown("### âœ… LoRAì˜ ì¥ì ")
    st.markdown(
        """
    - ğŸ’¾ **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ì „ì²´ íŒŒë¼ë¯¸í„°ì˜ 0.1% ë¯¸ë§Œë§Œ í•™ìŠµ
    - âš¡ **ë¹ ë¥¸ í•™ìŠµ**: ì‘ì€ í–‰ë ¬ë§Œ ì—…ë°ì´íŠ¸í•˜ì—¬ ë¹ ë¦„
    - ğŸ”§ **ê°„ë‹¨í•¨**: êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ì•ˆì •ì 
    - ğŸ“± **ëª¨ë°”ì¼ ì¹œí™”ì **: ì‘ì€ ëª¨ë¸ë¡œ ë°°í¬ ê°€ëŠ¥
    - ğŸ”„ **í˜¸í™˜ì„±**: ê¸°ì¡´ ëª¨ë¸ê³¼ ì™„ë²½ í˜¸í™˜
    """
    )

with col2:
    st.markdown("### âš ï¸ LoRAì˜ ë‹¨ì ")
    st.markdown(
        """
    - ğŸ¯ **ì„±ëŠ¥ ì œí•œ**: rankê°€ ë‚®ì„ìˆ˜ë¡ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ
    - ğŸ” **í•˜ì´í¼íŒŒë¼ë¼ë¯¸í„°**: r, alpha ê°’ì„ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •í•´ì•¼ í•¨
    - ğŸ“Š **ëª¨ë¸ í¬ê¸°**: ì–´ëŒ‘í„°ë¥¼ ì¶”ê°€ë¡œ ì €ì¥í•´ì•¼ í•¨
    - ğŸ§® **ì¶”ë¡  ì˜¤ë²„í—¤ë“œ**: ì•½ê°„ì˜ ì¶”ê°€ ê³„ì‚° í•„ìš”
    """
    )

# ì‹¤ìŠµ ì„¹ì…˜
st.markdown("---")
st.markdown("## ğŸš€ LoRA ì‹¤ìŠµí•˜ê¸°")

st.info(
    """
ğŸ’¡ **ì‹¤ìŠµ íŒ**:
- **r (rank)**: 8-32ê°€ ì¢‹ì€ ì‹œì‘ì , ë‚®ì„ìˆ˜ë¡ ë¹ ë¥´ì§€ë§Œ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ
- **alpha**: ë³´í†µ rì˜ 2ë°°ë¡œ ì„¤ì • (r=8ì´ë©´ alpha=16)
- **dropout**: 0.05-0.1 ì •ë„ê°€ ì ë‹¹, ê³¼ì í•© ë°©ì§€
- **target_modules**: GPT-2ì—ì„œëŠ” 'c_attn,c_proj'ê°€ ì¼ë°˜ì 
"""
)

if st.button("ğŸš€ LoRA ë°ëª¨ í•™ìŠµ ì‹¤í–‰", type="primary"):
    with st.spinner("LoRA ëª¨ë¸ ì¤€ë¹„ ì¤‘..."):
        base, tok, _ = load_base_model(model_id, four_bit=False)
        train_ds, eval_ds = load_tiny_instruct()
        tm = [s.strip() for s in target_modules.split(",") if s.strip()]

        # í•™ìŠµ ì§„í–‰ë¥  í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()

        for i in range(3):
            if i == 0:
                status_text.text("ë‹¨ê³„ 1/3: ëª¨ë¸ ì¤€ë¹„")
            elif i == 1:
                status_text.text("ë‹¨ê³„ 2/3: LoRA ì–´ëŒ‘í„° êµ¬ì„±")
            else:
                status_text.text("ë‹¨ê³„ 3/3: í•™ìŠµ ì‹œì‘")
            progress_bar.progress((i + 1) * 0.33)
            import time

            time.sleep(0.5)

        # ì‹¤ì œ í•™ìŠµ ì‹¤í–‰
        try:
            metrics = train_once(
                base,
                tok,
                train_ds,
                eval_ds,
                method="lora",
                r=r,
                alpha=alpha,
                dropout=dropout,
                target_modules=tm,
                epochs=epochs,
                lr=lr,
            )

            st.success("ğŸ‰ LoRA í•™ìŠµ ì™„ë£Œ!")

            # ê²°ê³¼ ì‹œê°í™”
            col1, col2 = st.columns(2)

            with col1:
                st.metric("í•™ìŠµ ì†ì‹¤", f"{metrics.get('train_loss', 'N/A'):.4f}")
                st.metric("í‰ê°€ ì†ì‹¤", f"{metrics.get('eval_loss', 'N/A'):.4f}")

            with col2:
                st.metric("í•™ìŠµ ì‹œê°„", f"{metrics.get('train_runtime', 'N/A'):.2f}ì´ˆ")
                st.metric(
                    "ìƒ˜í”Œ/ì´ˆ", f"{metrics.get('train_samples_per_second', 'N/A'):.2f}"
                )

            # íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± í‘œì‹œ
            st.markdown("### ğŸ“Š íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„±")

            # ì‹¤ì œ trainable params ê³„ì‚° (ì‹œë®¬ë ˆì´ì…˜)
            total_params = 103066  # ì˜ˆì‹œ ê°’
            trainable_params = r * 2 * len(tm) * 768  # ëŒ€ëµì ì¸ ê³„ì‚°
            efficiency = (trainable_params / total_params) * 100

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì „ì²´ íŒŒë¼ë¯¸í„°", f"{total_params:,}")
            with col2:
                st.metric("í•™ìŠµ íŒŒë¼ë¯¸í„°", f"{trainable_params:,}")
            with col3:
                st.metric("íš¨ìœ¨ì„±", f"{efficiency:.2f}%")

        except Exception as e:
            st.error(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# ì¶”ê°€ ì •ë³´
st.markdown("---")
st.markdown("## ğŸ“š ë” ì•Œì•„ë³´ê¸°")

with st.expander("ğŸ” LoRA ë…¼ë¬¸ ì •ë³´"):
    st.markdown(
        """
    **ë…¼ë¬¸**: "LoRA: Low-Rank Adaptation of Large Language Models" (2021)
    **ì €ì**: Edward J. Hu, et al.
    **í•µì‹¬ ì•„ì´ë””ì–´**: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì €ë­í¬ í–‰ë ¬ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ë¯¸ì„¸ì¡°ì •
    """
    )

with st.expander("ğŸ’¡ ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€"):
    st.markdown(
        """
    - **ChatGPT**: OpenAIì˜ ëŒ€í™”í˜• AI ëª¨ë¸
    - **Claude**: Anthropicì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸
    - **ì½”ë“œ ìƒì„±**: GitHub Copilot ë“±
    - **ë²ˆì—­**: ë‹¤êµ­ì–´ ë²ˆì—­ ëª¨ë¸
    - **ìš”ì•½**: ê¸´ ë¬¸ì„œ ìš”ì•½ ëª¨ë¸
    """
    )

with st.expander("âš¡ ì„±ëŠ¥ ë¹„êµ"):
    st.markdown(
        """
    | ë°©ë²• | íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± | ì„±ëŠ¥ | í•™ìŠµ ì†ë„ | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ |
    |------|----------------|------|-----------|---------------|
    | Full Fine-tuning | ë‚®ìŒ | ë†’ìŒ | ëŠë¦¼ | ë†’ìŒ |
    | **LoRA** | **ë†’ìŒ** | **ë†’ìŒ** | **ë¹ ë¦„** | **ë‚®ìŒ** |
    | Prompt Tuning | ë†’ìŒ | ë³´í†µ | ë¹ ë¦„ | ë‚®ìŒ |
    """
    )

with st.expander("ğŸ”§ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­"):
    st.markdown(
        """
    - **í–‰ë ¬ ë¶„í•´**: W = Wâ‚€ + A Ã— B
    - **ì´ˆê¸°í™”**: AëŠ” ì •ê·œë¶„í¬, BëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™”
    - **ìŠ¤ì¼€ì¼ë§**: alpha/rë¡œ LoRA ì¶œë ¥ì„ ìŠ¤ì¼€ì¼ë§
    - **ë“œë¡­ì•„ì›ƒ**: ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ì •ê·œí™”
    - **íƒ€ê²Ÿ ëª¨ë“ˆ**: ì£¼ë¡œ attentionê³¼ projection ë ˆì´ì–´ì— ì ìš©
    """
    )
