import streamlit as st
import matplotlib.pyplot as plt
import numpy as np
from peft_utils.model import load_base_model, DEFAULT_MODEL_ID
from peft_utils.data import load_tiny_instruct
from peft_utils.train import train_once
from peft_utils.viz import setup_korean_font, create_comparison_chart

# í•œê¸€ í°íŠ¸ ì„¤ì •
setup_korean_font()

st.set_page_config(page_title="Prefix & Prompt Tuning - ê°€ìƒ í† í° í•™ìŠµ", page_icon="ğŸ“Œ", layout="wide")

st.title("ğŸ“Œ Prefix & Prompt Tuning â€” ê°€ìƒ í† í° í•™ìŠµ")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    model_id = st.text_input("Base model", value=DEFAULT_MODEL_ID, help="ê¸°ë³¸ ëª¨ë¸ ID")
    num_virtual_tokens = st.slider("ê°€ìƒ í† í° ìˆ˜", 1, 100, 16, step=1, help="ì¶”ê°€í•  ê°€ìƒ í† í°ì˜ ê°œìˆ˜")
    epochs = st.number_input("epochs", 1, 10, 1, help="í•™ìŠµ ì—í¬í¬ ìˆ˜")
    lr = st.number_input("learning_rate", 1e-6, 5e-3, 5e-4, step=1e-6, format="%.6f", help="í•™ìŠµë¥ ")
    
    st.markdown("---")
    st.markdown("### ğŸ”§ ë°©ë²• ì„ íƒ")
    method = st.selectbox("PEFT ë°©ë²•", ["prefix", "prompt"], 
                         help="Prefix Tuning: ì…ë ¥ì— ê°€ìƒ í† í° ì¶”ê°€\nPrompt Tuning: ì…ë ¥ ì‹œì‘ì—ë§Œ ê°€ìƒ í† í° ì¶”ê°€")

# ë©”ì¸ ì½˜í…ì¸ 
col1, col2 = st.columns([2, 1])

with col1:
    st.markdown("""
    ## ğŸ¯ Prefix & Prompt Tuningì´ë€ ë¬´ì—‡ì¼ê¹Œìš”?
    
    **Prefix & Prompt Tuning**ì€ ì…ë ¥ì— **ê°€ìƒ(soft) í† í°**ì„ ì¶”ê°€í•˜ì—¬ íƒœìŠ¤í¬ íŠ¹ì„±ì„ ì£¼ì…í•©ë‹ˆë‹¤.
    
    ### ğŸ§© ê¸°ì¡´ ë°©ì‹ì˜ í•œê³„
    - **í•˜ë“œì½”ë”©**: í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•¨
    - **ì¼ê´€ì„± ë¶€ì¡±**: í”„ë¡¬í”„íŠ¸ë§ˆë‹¤ ë‹¤ë¥¸ ê²°ê³¼
    - **ìµœì í™” ë¶ˆê°€**: í”„ë¡¬í”„íŠ¸ë¥¼ í•™ìŠµí•  ìˆ˜ ì—†ìŒ
    
    ### âœ¨ ê°€ìƒ í† í°ì˜ í•´ê²°ì±…
    - **í•™ìŠµ ê°€ëŠ¥**: í”„ë¡¬í”„íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ìµœì í™”
    - **ì¼ê´€ì„±**: ë™ì¼í•œ íƒœìŠ¤í¬ì— ì¼ê´€ëœ ê²°ê³¼
    - **íš¨ìœ¨ì„±**: ëª¨ë¸ íŒŒë¼ë¯¸í„°ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ
    """)

with col2:
    # ê°€ìƒ í† í° êµ¬ì¡° ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(6, 4))
    
    # í† í° ì‹œí€€ìŠ¤ ì‹œê°í™”
    tokens = ['[PREFIX]', '[PREFIX]', '[PREFIX]', 'Hello', 'world', '!']
    colors = ['red'] * 3 + ['blue'] * 3
    
    y_pos = np.arange(len(tokens))
    bars = ax.barh(y_pos, [1] * len(tokens), color=colors, alpha=0.7)
    ax.set_yticks(y_pos)
    ax.set_yticklabels(tokens)
    ax.set_xlabel('í† í° ìœ„ì¹˜')
    ax.set_title('ê°€ìƒ í† í° + ì‹¤ì œ í† í°')
    
    # ê°€ìƒ í† í° í‘œì‹œ
    ax.text(0.5, 1.5, 'ê°€ìƒ í† í° (í•™ìŠµ ê°€ëŠ¥)', ha='center', va='center', 
            bbox=dict(boxstyle="round,pad=0.3", facecolor="red", alpha=0.7))
    ax.text(0.5, 4.5, 'ì‹¤ì œ í† í° (ê³ ì •)', ha='center', va='center',
            bbox=dict(boxstyle="round,pad=0.3", facecolor="blue", alpha=0.7))
    
    plt.tight_layout()
    st.pyplot(fig)

# ìƒì„¸ ì„¤ëª…
st.markdown("---")
st.markdown("""
## ğŸ”¬ ì‘ë™ ì›ë¦¬

### ğŸ“Š í•µì‹¬ ì•„ì´ë””ì–´
```
ì…ë ¥: [PREFIX] [PREFIX] ... [PREFIX] + ì‹¤ì œ í…ìŠ¤íŠ¸
ì¶œë ¥: íƒœìŠ¤í¬ì— ìµœì í™”ëœ ì‘ë‹µ
```

### ğŸ¨ Prefix vs Prompt Tuning
""")

# Prefix vs Prompt Tuning ë¹„êµ
col1, col2 = st.columns(2)

with col1:
    st.markdown("#### ğŸ”´ Prefix Tuning")
    fig, ax = plt.subplots(figsize=(5, 4))
    
    # Prefix Tuning êµ¬ì¡°
    ax.text(0.5, 0.9, 'ì…ë ¥ í…ìŠ¤íŠ¸', ha='center', va='center', fontsize=10,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
    ax.arrow(0.5, 0.8, 0, -0.2, head_width=0.05, head_length=0.05, fc='red', ec='red')
    ax.text(0.5, 0.6, 'ê°€ìƒ í† í° ì¶”ê°€', ha='center', va='center', fontsize=10,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightcoral"))
    ax.arrow(0.5, 0.5, 0, -0.2, head_width=0.05, head_length=0.05, fc='red', ec='red')
    ax.text(0.5, 0.3, 'ì „ì²´ ëª¨ë¸ í•™ìŠµ', ha='center', va='center', fontsize=10,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"))
    ax.text(0.5, 0.1, 'ì„±ëŠ¥: ë†’ìŒ', ha='center', va='center', fontsize=10,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"))
    
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.set_title('Prefix Tuning')
    ax.axis('off')
    
    st.pyplot(fig)

with col2:
    st.markdown("#### ğŸŸ¢ Prompt Tuning")
    fig, ax = plt.subplots(figsize=(5, 4))
    
    # Prompt Tuning êµ¬ì¡°
    ax.text(0.5, 0.9, 'ì…ë ¥ í…ìŠ¤íŠ¸', ha='center', va='center', fontsize=10,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
    ax.arrow(0.5, 0.8, 0, -0.2, head_width=0.05, head_length=0.05, fc='orange', ec='orange')
    ax.text(0.5, 0.6, 'ì‹œì‘ì—ë§Œ ì¶”ê°€', ha='center', va='center', fontsize=10,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow"))
    ax.arrow(0.5, 0.5, 0, -0.2, head_width=0.05, head_length=0.05, fc='orange', ec='orange')
    ax.text(0.5, 0.3, 'ê°€ìƒ í† í°ë§Œ í•™ìŠµ', ha='center', va='center', fontsize=10,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"))
    ax.text(0.5, 0.1, 'íš¨ìœ¨ì„±: ë†’ìŒ', ha='center', va='center', fontsize=10,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"))
    
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.set_title('Prompt Tuning')
    ax.axis('off')
    
    st.pyplot(fig)

# ê°€ìƒ í† í° í•™ìŠµ ê³¼ì •
st.markdown("---")
st.markdown("## ğŸ¯ ê°€ìƒ í† í° í•™ìŠµ ê³¼ì •")

col1, col2 = st.columns(2)

with col1:
    st.markdown("### ğŸ“Š í•™ìŠµ ê³¼ì •")
    
    # í•™ìŠµ ê³¼ì • ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(6, 4))
    
    # í•™ìŠµ ë‹¨ê³„ë³„ ê°€ìƒ í† í° ë³€í™”
    steps = np.linspace(0, 10, 100)
    token1 = 0.5 + 0.5 * np.sin(steps * 1.5) + np.random.normal(0, 0.1, 100)
    token2 = 0.3 + 0.7 * np.sin(steps * 2.0) + np.random.normal(0, 0.1, 100)
    token3 = 0.7 + 0.3 * np.sin(steps * 1.0) + np.random.normal(0, 0.1, 100)
    
    ax.plot(steps, token1, 'r-', linewidth=2, label='ê°€ìƒ í† í° 1', alpha=0.7)
    ax.plot(steps, token2, 'g-', linewidth=2, label='ê°€ìƒ í† í° 2', alpha=0.7)
    ax.plot(steps, token3, 'b-', linewidth=2, label='ê°€ìƒ í† í° 3', alpha=0.7)
    
    ax.set_xlabel('í•™ìŠµ ë‹¨ê³„')
    ax.set_ylabel('í† í° ì„ë² ë”© ê°’')
    ax.set_title('ê°€ìƒ í† í° í•™ìŠµ ê³¼ì •')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    st.pyplot(fig)

with col2:
    st.markdown("### âš¡ íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„±")
    
    # íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± ë¹„êµ
    methods = ['Full Fine-tuning', 'LoRA', 'Prefix Tuning', 'Prompt Tuning']
    param_counts = [100, 0.8, 0.1, 0.05]  # ë°±ë¶„ìœ¨ë¡œ í‘œì‹œ
    
    fig, ax = plt.subplots(figsize=(6, 4))
    bars = ax.bar(methods, param_counts, color=['red', 'orange', 'yellow', 'green'], alpha=0.7)
    ax.set_ylabel('í•™ìŠµ íŒŒë¼ë¯¸í„° (%)')
    ax.set_title('íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± ë¹„êµ')
    ax.set_ylim(0, 110)
    
    # ê°’ í‘œì‹œ
    for bar, count in zip(bars, param_counts):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{count}%', ha='center', va='bottom')
    
    plt.xticks(rotation=45)
    plt.tight_layout()
    st.pyplot(fig)

# ì¥ë‹¨ì 
st.markdown("---")
col1, col2 = st.columns(2)

with col1:
    st.markdown("### âœ… ê°€ìƒ í† í°ì˜ ì¥ì ")
    st.markdown("""
    - ğŸ¯ **íƒœìŠ¤í¬ íŠ¹í™”**: íŠ¹ì • ì‘ì—…ì— ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸
    - ğŸ’¾ **íš¨ìœ¨ì„±**: ëª¨ë¸ íŒŒë¼ë¯¸í„°ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ
    - ğŸ”§ **ìœ ì—°ì„±**: ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì— ì‰½ê²Œ ì ìš©
    - ğŸ“± **ê²½ëŸ‰í™”**: ë§¤ìš° ì‘ì€ ì–´ëŒ‘í„°ë§Œ ì €ì¥
    - ğŸ”„ **ì¬ì‚¬ìš©**: í•™ìŠµëœ ê°€ìƒ í† í°ì„ ë‹¤ë¥¸ ëª¨ë¸ì— ì ìš©
    """)

with col2:
    st.markdown("### âš ï¸ ê°€ìƒ í† í°ì˜ ë‹¨ì ")
    st.markdown("""
    - ğŸ¯ **ì„±ëŠ¥ ì œí•œ**: ë³µì¡í•œ íƒœìŠ¤í¬ì—ì„œëŠ” ì„±ëŠ¥ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ
    - ğŸ“ **ê¸¸ì´ ì œí•œ**: ê°€ìƒ í† í° ìˆ˜ì— ë”°ë¥¸ ì„±ëŠ¥ ì œí•œ
    - ğŸ” **í•´ì„ ì–´ë ¤ì›€**: ê°€ìƒ í† í°ì˜ ì˜ë¯¸ í•´ì„ì´ ì–´ë ¤ì›€
    - ğŸ§® **í•˜ì´í¼íŒŒë¼ë¯¸í„°**: ê°€ìƒ í† í° ìˆ˜ ì„¤ì • í•„ìš”
    """)

# ì‹¤ìŠµ ì„¹ì…˜
st.markdown("---")
st.markdown("## ğŸš€ Prefix & Prompt Tuning ì‹¤ìŠµí•˜ê¸°")

st.info("""
ğŸ’¡ **ì‹¤ìŠµ íŒ**: 
- **ê°€ìƒ í† í° ìˆ˜**: 16-64ê°€ ì¢‹ì€ ì‹œì‘ì 
- **Prefix Tuning**: ë” ë‚˜ì€ ì„±ëŠ¥, ë” ë§ì€ íŒŒë¼ë¯¸í„°
- **Prompt Tuning**: ë” íš¨ìœ¨ì , ë” ì ì€ íŒŒë¼ë¯¸í„°
- **ì£¼ì˜**: í˜„ì¬ í™˜ê²½ì—ì„œëŠ” ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŒ
""")

if st.button("ğŸš€ ê°€ìƒ í† í° ë°ëª¨ í•™ìŠµ ì‹¤í–‰", type="primary"):
    with st.spinner(f"{method.upper()} ëª¨ë¸ ì¤€ë¹„ ì¤‘..."):
        try:
            base, tok, _ = load_base_model(model_id, four_bit=False)
            train_ds, eval_ds = load_tiny_instruct()
            
            # í•™ìŠµ ì§„í–‰ë¥  í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i in range(4):
                if i == 0:
                    status_text.text("ë‹¨ê³„ 1/4: ëª¨ë¸ ì¤€ë¹„")
                elif i == 1:
                    status_text.text("ë‹¨ê³„ 2/4: ê°€ìƒ í† í° ì´ˆê¸°í™”")
                elif i == 2:
                    status_text.text("ë‹¨ê³„ 3/4: ì–´ëŒ‘í„° êµ¬ì„±")
                else:
                    status_text.text("ë‹¨ê³„ 4/4: í•™ìŠµ ì‹œì‘")
                progress_bar.progress((i + 1) * 0.25)
                import time
                time.sleep(0.5)
            
            # ì‹¤ì œ í•™ìŠµ ì‹¤í–‰
            metrics = train_once(base, tok, train_ds, eval_ds, method=method,
                               num_virtual_tokens=num_virtual_tokens, epochs=epochs, lr=lr)
            
            st.success(f"ğŸ‰ {method.upper()} í•™ìŠµ ì™„ë£Œ!")
            
            # ê²°ê³¼ ì‹œê°í™”
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("í•™ìŠµ ì†ì‹¤", f"{metrics.get('train_loss', 'N/A'):.4f}")
                st.metric("í‰ê°€ ì†ì‹¤", f"{metrics.get('eval_loss', 'N/A'):.4f}")
            
            with col2:
                st.metric("í•™ìŠµ ì‹œê°„", f"{metrics.get('train_runtime', 'N/A'):.2f}ì´ˆ")
                st.metric("ìƒ˜í”Œ/ì´ˆ", f"{metrics.get('train_samples_per_second', 'N/A'):.2f}")
            
            # ê°€ìƒ í† í° ì •ë³´ í‘œì‹œ
            st.markdown("### ğŸ“Œ ê°€ìƒ í† í° ì •ë³´")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ê°€ìƒ í† í° ìˆ˜", num_virtual_tokens)
            with col2:
                st.metric("í•™ìŠµ íŒŒë¼ë¯¸í„°", f"{num_virtual_tokens * 768:,}")
            with col3:
                st.metric("ë°©ë²•", method.upper())
            
        except Exception as e:
            st.error(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.info("ğŸ’¡ í˜„ì¬ í™˜ê²½ì—ì„œ Prefix/Prompt Tuningì´ ì§€ì›ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. LoRAë‚˜ IAÂ³ë¥¼ ëŒ€ì‹  ì‚¬ìš©í•´ë³´ì„¸ìš”.")

# ì¶”ê°€ ì •ë³´
st.markdown("---")
st.markdown("## ğŸ“š ë” ì•Œì•„ë³´ê¸°")

with st.expander("ğŸ” ë…¼ë¬¸ ì •ë³´"):
    st.markdown("""
    **Prefix Tuning**: "Prefix-Tuning: Optimizing Continuous Prompts for Generation" (2021)
    **Prompt Tuning**: "The Power of Scale for Parameter-Efficient Prompt Tuning" (2021)
    **í•µì‹¬ ì•„ì´ë””ì–´**: ì…ë ¥ì— í•™ìŠµ ê°€ëŠ¥í•œ ê°€ìƒ í† í°ì„ ì¶”ê°€í•˜ì—¬ íƒœìŠ¤í¬ íŠ¹í™”
    """)

with st.expander("ğŸ’¡ ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€"):
    st.markdown("""
    - **ë²ˆì—­**: ì–¸ì–´ë³„ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸
    - **ìš”ì•½**: ë¬¸ì„œ ìš”ì•½ íƒœìŠ¤í¬ ìµœì í™”
    - **ëŒ€í™”**: ëŒ€í™”í˜• AI ì„±ê²© ì„¤ì •
    - **ì½”ë“œ ìƒì„±**: í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë³„ ìµœì í™”
    """)

with st.expander("âš¡ ì„±ëŠ¥ ë¹„êµ"):
    st.markdown("""
    | ë°©ë²• | íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± | ì„±ëŠ¥ | í•™ìŠµ ì†ë„ | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ |
    |------|----------------|------|-----------|---------------|
    | Full Fine-tuning | ë‚®ìŒ | ë†’ìŒ | ëŠë¦¼ | ë†’ìŒ |
    | LoRA | ë†’ìŒ | ë†’ìŒ | ë¹ ë¦„ | ì¤‘ê°„ |
    | **Prefix Tuning** | **ë†’ìŒ** | **ë†’ìŒ** | **ë¹ ë¦„** | **ë‚®ìŒ** |
    | **Prompt Tuning** | **ë§¤ìš° ë†’ìŒ** | **ë³´í†µ** | **ë§¤ìš° ë¹ ë¦„** | **ë§¤ìš° ë‚®ìŒ** |
    """)

with st.expander("ğŸ”§ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­"):
    st.markdown("""
    - **ê°€ìƒ í† í°**: í•™ìŠµ ê°€ëŠ¥í•œ ì„ë² ë”© ë²¡í„°
    - **ìœ„ì¹˜**: ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ì‹œì‘ ë˜ëŠ” ì¤‘ê°„ì— ì‚½ì…
    - **í•™ìŠµ**: íƒœìŠ¤í¬ë³„ ì†ì‹¤ í•¨ìˆ˜ë¡œ ìµœì í™”
    - **ì €ì¥**: ì‘ì€ ì–´ëŒ‘í„° íŒŒì¼ë¡œ ì €ì¥
    """)
